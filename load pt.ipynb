{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26b287c4-646b-409b-a888-ecf0f483f23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87993aea-4019-4416-be1b-cad527a8d31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = torch.load(\"C:/Users/Marc/Desktop/model_data/model_target (309).pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e346d11f-4bf9-44a3-9104-b571dbeda9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 2636800])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88e73594-ff8b-4e91-b00a-3bed6e265ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(val.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "16965112-a37c-4ed8-acd3-15de65227bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "\n",
    "class data_loader(Dataset):\n",
    "    \"\"\"\n",
    "    This dataloader loads the tensor input and target\n",
    "    \"\"\"\n",
    "    def __init__(self, path: str, ind: list, device):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            path (str): path to the input & target folder.\n",
    "            ind (list): list of indices for which pictures to load.\n",
    "            device (class 'torch.device'): which pytorch device the data should\n",
    "            be sent to.\n",
    "        \"\"\"\n",
    "\n",
    "        self.device = device\n",
    "        self.imgs_path = path\n",
    "        self.data = []\n",
    "        for i in ind:\n",
    "            self.data.append([self.imgs_path + f\"/model_input ({i}).pt\",\n",
    "                        self.imgs_path + f\"/model_target ({i}).pt\"])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_path, target_path = self.data[idx] # path for target + input\n",
    "\n",
    "        inp = torch.load(input_path) # load the input data\n",
    "        inp = inp.type(torch.float).to(self.device)\n",
    "\n",
    "        tar = torch.load(target_path) # load the target data\n",
    "        tar = tar.type(torch.float).to(self.device)\n",
    "\n",
    "        return inp, tar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "4c7b1c02-8ba0-406d-93c3-e8d08a8b4806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "5c81194b-59e8-4031-8db4-7bec23df4984",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainload = data_loader(path = \"C:/Users/Marc/Desktop/model_data\", ind = [i for i in range(1, 310 + 1)], device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "1fdedcd1-83fc-4b11-9700-3fe74538f028",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "\n",
    "# Set up the dataloaders:\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainload,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "e108b811-d5f1-4af0-bb7c-e31a607a3978",
   "metadata": {},
   "outputs": [],
   "source": [
    "load = iter(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "8e9e78dc-7418-4f9e-8043-e7fa2c7cc17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 21, 346000])"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = next(load)\n",
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "50f3a66e-00d4-4a97-a12d-ce398ad37a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 21, 346000])"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "3b250d5c-517c-45c9-9e62-0b0918d4c7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "m = nn.Conv1d(16, 33, 3, stride=1)\n",
    "input = torch.randn(1, 16, 50)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "4682c057-fc8e-44a4-b924-10adea705998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 50])"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "6a8220da-48e0-41e2-9ea0-23753393e61b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 33, 48])"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "89bf8e94-793f-41b4-b56c-b19e8979c8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Conv1d(21, 22, 3, stride=1).to(device)\n",
    "output = m(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "29b65357-0400-49a5-b125-ac23a9858c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 21, 346000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 22, 345998])"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data[0].shape)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "798ca028-1c4b-45c0-bd9a-4b2296ea53fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "m2 = nn.Conv2d(1, 3, kernel_size=3).to(device)\n",
    "out = m2(torch.reshape(data[0], (1, 1, 21, 346000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "2097aa5c-18c7-4f4a-a51a-8bb5a5d18f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 19, 345998])"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b83c79-998b-4568-afb1-562bb0e8bcf7",
   "metadata": {},
   "source": [
    " Create model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a348c5-ec07-4439-9aec-3ae68ad286b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "ff9c1d5e-410d-4e95-8de4-323170382df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.5000, 3.5000, 5.5000]]])"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.AvgPool1d(2, stride=2)\n",
    "m(torch.tensor([[[1.,2,3,4,5,6,7]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "1d0ed472-0529-49dc-8f53-c7a406089359",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.ConvTranspose1d(21, 22, 3, stride=1).to(device)\n",
    "output = m(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "0e436edc-3e01-448d-a670-e94d62aef84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 21, 346000])"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "21e380d3-5ca0-4ea6-aed5-0dd272ddc50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 22, 346002])"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "36877095-76c3-4e2a-ba71-2acc06568d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = nn.Conv1d(21, 22, 3, stride=1).to(device)\n",
    "m2 = nn.ConvTranspose1d(22, 21, 3, stride=1).to(device)\n",
    "out1 = m1(data[0])\n",
    "out2 = m2(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "2c61a458-39a8-4e84-8727-60e7acbd17cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 21, 346000])\n",
      "torch.Size([1, 22, 345998])\n",
      "torch.Size([1, 21, 346000])\n"
     ]
    }
   ],
   "source": [
    "print(data[0].shape)\n",
    "print(out1.shape)\n",
    "print(out2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6eac79-00e5-4d81-b6e7-a7cd2503078c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(nn.Module): # test model\n",
    "    def __init__(self, 1, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 3, 3, stride=2) # 1 channel input, 3 channel outputs and kernel size of 3.\n",
    "        self.pool = nn.AvgPool1d(2, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(x)\n",
    "        x = self.doub(x)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
