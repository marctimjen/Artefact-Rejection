{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "e7fe5bed-a1d7-4b53-bb15-d1337f4b9ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class load_whole_data(Dataset): \n",
    "    \"\"\"\n",
    "    This dataloader loads the tensor input and target in whole\n",
    "    \"\"\"\n",
    "    def __init__(self, path: str, ind: list):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            path (str): path to the input & target folder.\n",
    "            ind (list): list of indices for which pictures to load.\n",
    "            device (class 'torch.device'): which pytorch device the data should\n",
    "            be sent to.\n",
    "        \"\"\"\n",
    "\n",
    "        self.device = \"cpu\"\n",
    "        self.imgs_path = path\n",
    "        self.data = []\n",
    "        for i in ind:\n",
    "            self.data.append([self.imgs_path + f\"/model_input ({i}).pt\",\n",
    "                        self.imgs_path + f\"/model_target ({i}).pt\"])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_path, target_path = self.data[idx] # path for target + input\n",
    "\n",
    "        inp = torch.load(input_path) # load the input data\n",
    "        inp = inp.type(torch.float).to(self.device)\n",
    "\n",
    "        tar = torch.load(target_path) # load the target data\n",
    "        tar = tar.type(torch.float).to(self.device)\n",
    "\n",
    "        return inp, tar\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "class load_shuffle_5_min(Dataset): \n",
    "    \"\"\"\n",
    "    This dataloader loads the tensor input and target in whole\n",
    "    \"\"\"\n",
    "    def __init__(self, ls: list, device):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            path (str): path to the input & target folder.\n",
    "            ind (list): list of indices for which pictures to load.\n",
    "            device (class 'torch.device'): which pytorch device the data should\n",
    "            be sent to.\n",
    "        \"\"\"\n",
    "\n",
    "        self.device = device\n",
    "        self.ls = ls # list with the input and target data\n",
    "        self.size = (ls[0][0].shape[0], ls[0][0].shape[1]) # size of target and input\n",
    "        \n",
    "        length = math.floor((self.size[1]/(250*60*5)))*self.size[0] # the amount of total possible cuts\n",
    "        self.length = int(min((75 - 75 % self.size[0]), length))\n",
    "        \n",
    "        self.gen = iter(self.create_data(self.length))\n",
    "        \n",
    "        #print(self.length)\n",
    "\n",
    "    \n",
    "\n",
    "    def create_data(self, nr_of_cuts):       \n",
    "        cut_point = np.random.randint(low = 250*60*0.5, high = self.size[1] - 250*60*5, \n",
    "                          size = nr_of_cuts) # choose the place to cut\n",
    "        \n",
    "        cuts_pr_chan = nr_of_cuts/self.size[0] # the amount of cuts pr channel\n",
    "        \n",
    "        for i in range(nr_of_cuts):\n",
    "            inp = self.ls[0][0][int(i//cuts_pr_chan)][cut_point[i]:cut_point[i]+60*250*5]\n",
    "            tar = self.ls[1][0][int(i//cuts_pr_chan)][cut_point[i]:cut_point[i]+60*250*5]\n",
    "            yield (inp, tar)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inp, tar = next(self.gen)\n",
    "        inp = inp.to(self.device)\n",
    "        tar = tar.to(self.device)\n",
    "        return inp, tar\n",
    "\n",
    "    \n",
    "    \n",
    "class load_shuffle_5_min_all(Dataset): \n",
    "    \"\"\"\n",
    "    This dataloader loads the tensor input and target in whole\n",
    "    \"\"\"\n",
    "    def __init__(self, ls: list, device):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            path (str): path to the input & target folder.\n",
    "            ind (list): list of indices for which pictures to load.\n",
    "            device (class 'torch.device'): which pytorch device the data should\n",
    "            be sent to.\n",
    "        \"\"\"\n",
    "\n",
    "        self.device = device\n",
    "        self.ls = ls # list with the input and target data\n",
    "        self.size = (ls[0][0].shape[0], ls[0][0].shape[1]) # size of target and input\n",
    "        \n",
    "        self.length = math.floor((self.size[1]/(250*60*5)))*self.size[0] # the amount of total possible cuts\n",
    "\n",
    "        \n",
    "        self.gen = iter(self.create_data(self.length))\n",
    "        #print(self.length)\n",
    "\n",
    "    \n",
    "\n",
    "    def create_data(self, nr_of_cuts):       \n",
    "        cut_point = np.random.randint(low = 250*60*0.5, high = self.size[1] - 250*60*5, \n",
    "                          size = nr_of_cuts) # choose the place to cut\n",
    "        \n",
    "        cuts_pr_chan = nr_of_cuts/self.size[0] # the amount of cuts pr channel\n",
    "        \n",
    "        for i in range(nr_of_cuts):\n",
    "            inp = self.ls[0][0][int(i//cuts_pr_chan)][cut_point[i]:cut_point[i]+60*250*5]\n",
    "            tar = self.ls[1][0][int(i//cuts_pr_chan)][cut_point[i]:cut_point[i]+60*250*5]\n",
    "            yield (inp, tar)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inp, tar = next(self.gen)\n",
    "        inp = inp.to(self.device)\n",
    "        tar = tar.to(self.device)\n",
    "        return inp, tar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "2c3c5579-e116-4d8c-9c1d-70670c8e5232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "j = 40\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "trainload = load_whole_data(path = \"C:/Users/Marc/Desktop/model_data\", ind = [i for i in range(1, 283 + 1)])\n",
    "batch_size = 1\n",
    "\n",
    "# Set up the dataloaders:\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainload,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=0)\n",
    "load = iter(trainloader)\n",
    "\n",
    "loader2 = load_shuffle_5_min(next(load), \"cpu\")\n",
    "batch_size = 1\n",
    "\n",
    "# Set up the dataloaders:\n",
    "\n",
    "loader2 = torch.utils.data.DataLoader(loader2,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=0)\n",
    "\n",
    "load2 = iter(loader2)\n",
    "\n",
    "j = 0\n",
    "for i in loader2:\n",
    "    j += 1\n",
    "\n",
    "print(\"j =\", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "4e5c38b5-0715-4303-88dd-5d5ef980c6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "time: 31.01079511642456\n",
      "Number of files loaded in total: 283\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "trainload = load_whole_data(path = \"C:/Users/Marc/Desktop/model_data\", ind = [i for i in range(1, 283 + 1)])\n",
    "\n",
    "# Set up the dataloaders:\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainload,\n",
    "                                          batch_size=1,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=0)\n",
    "\n",
    "data = []\n",
    "\n",
    "nr_of_files_loaded = 0\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for file in trainloader:\n",
    "    loader2 = load_shuffle_5_min(file, device)\n",
    "    loader2 = torch.utils.data.DataLoader(loader2,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=0)\n",
    "    nr_of_files_loaded += 1\n",
    "    j = 0\n",
    "    for i in loader2:\n",
    "        j += 1\n",
    "    \n",
    "    data.append(j)\n",
    "\n",
    "print(\"time:\", time.time()-start)\n",
    "    \n",
    "print(\"Number of files loaded in total:\", nr_of_files_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "84e0d96f-eea4-4c89-a31e-f335370e484a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "time: 26.296545028686523\n",
      "Number of files loaded in total: 283\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "device = \"cpu\"\n",
    "print(device)\n",
    "\n",
    "trainload = load_whole_data(path = \"C:/Users/Marc/Desktop/model_data\", ind = [i for i in range(1, 283 + 1)])\n",
    "\n",
    "# Set up the dataloaders:\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainload,\n",
    "                                          batch_size=1,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=0)\n",
    "\n",
    "data_after = []\n",
    "\n",
    "nr_of_files_loaded = 0\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for file in trainloader:\n",
    "    loader2 = load_shuffle_5_min(file, device)\n",
    "    loader2 = torch.utils.data.DataLoader(loader2,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=0)\n",
    "    nr_of_files_loaded += 1\n",
    "    j = 0\n",
    "    for i in loader2:\n",
    "        j += 1\n",
    "    \n",
    "    data_after.append(j)\n",
    "\n",
    "print(\"time:\", time.time()-start)\n",
    "    \n",
    "print(\"Number of files loaded in total:\", nr_of_files_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958bd52d-0ead-4784-80e9-274bc72b1084",
   "metadata": {},
   "source": [
    "Lets do the data analysis before we did the corrections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "7fdb875c-2088-4872-a80f-019bd4dfb54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "time: 26.10477352142334\n",
      "Number of files loaded in total: 283\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "device = \"cpu\"\n",
    "print(device)\n",
    "\n",
    "trainload = load_whole_data(path = \"C:/Users/Marc/Desktop/model_data\", ind = [i for i in range(1, 283 + 1)])\n",
    "\n",
    "# Set up the dataloaders:\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainload,\n",
    "                                          batch_size=1,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=0)\n",
    "\n",
    "data_before = []\n",
    "\n",
    "nr_of_files_loaded = 0\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for file in trainloader:\n",
    "    loader2 = load_shuffle_5_min_all(file, device)\n",
    "    loader2 = torch.utils.data.DataLoader(loader2,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=0)\n",
    "    nr_of_files_loaded += 1\n",
    "    j = 0\n",
    "    for i in loader2:\n",
    "        j += 1\n",
    "    \n",
    "    data_before.append(j)\n",
    "\n",
    "print(\"time:\", time.time()-start)\n",
    "    \n",
    "print(\"Number of files loaded in total:\", nr_of_files_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "e1aaf81e-403e-4f6e-af8c-f7e5c8e507ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.76678445229682\n",
      "76.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "m = plt.hist(data_before, bins = 30)\n",
    "\n",
    "print(np.mean(data_before))\n",
    "print(np.median(data_before))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "c24ca77a-d9e6-408c-9f37-223d490fe1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.667844522968196\n",
      "66.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "m = plt.hist(data_after, bins = 30)\n",
    "\n",
    "print(np.mean(data_after))\n",
    "print(np.median(data_after))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
