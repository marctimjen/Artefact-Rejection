{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c944e3d-955f-439d-a5c4-d229c95a2f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune.new as neptune\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import torch.multiprocessing as mp\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") # adds higher directory to python modules path\n",
    "\n",
    "from LoaderPACK.LSTM_net import LSTM_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b0dcfc-c5ec-4895-bb3e-aa38ff1ef788",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b2fdc51-c887-416d-9d4d-1a3bb0d28f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = torch.load(r\"C:\\Users\\Marc\\Desktop\\Wierd output\\ind.pt\").to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b934ce06-da56-4f7a-b394-1e182376b9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 60000])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8454bf91-ee40-465e-b88e-913fde6cc3d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  5.7873,   2.8735,   4.3204,  ...,   1.8193,  -0.2992,  -0.6758]],\n",
       "\n",
       "        [[  4.0954,   8.0991,   6.5922,  ...,  26.7045,  24.6322,  19.7239]],\n",
       "\n",
       "        [[  7.6339,  10.7983,  11.2701,  ...,  -2.8396,  -6.4964,  -8.3752]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ -7.6907,   0.3859,  22.7656,  ...,  -8.1175, -17.1491, -16.2881]],\n",
       "\n",
       "        [[ 21.8641,  12.8339,  16.2406,  ...,  -4.5149,  -7.0672,  -8.2953]],\n",
       "\n",
       "        [[ -0.3570,   0.5192,   1.3458,  ...,  -2.6831,  -9.9697,   5.9507]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16a1a88a-1649-4337-a625-ec42088e301a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "device = \"cpu\"\n",
    "\n",
    "model = LSTM_net(batch_size=batch_size, device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1b359bd-9ef1-40cb-96ec-7cf3121f04da",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8aba3af-c345-48c6-94e8-f850c3f73b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2642, 0.2583, 0.2553,  ..., 0.2486, 0.2481, 0.2472],\n",
       "         [0.7358, 0.7417, 0.7447,  ..., 0.7514, 0.7519, 0.7528]],\n",
       "\n",
       "        [[0.2647, 0.2595, 0.2563,  ..., 0.2526, 0.2525, 0.2508],\n",
       "         [0.7353, 0.7405, 0.7437,  ..., 0.7474, 0.7475, 0.7492]],\n",
       "\n",
       "        [[0.2655, 0.2604, 0.2574,  ..., 0.2460, 0.2458, 0.2455],\n",
       "         [0.7345, 0.7396, 0.7426,  ..., 0.7540, 0.7542, 0.7545]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.2610, 0.2569, 0.2553,  ..., 0.2470, 0.2465, 0.2461],\n",
       "         [0.7390, 0.7431, 0.7447,  ..., 0.7530, 0.7535, 0.7539]],\n",
       "\n",
       "        [[0.2652, 0.2602, 0.2572,  ..., 0.2461, 0.2462, 0.2458],\n",
       "         [0.7348, 0.7398, 0.7428,  ..., 0.7539, 0.7538, 0.7542]],\n",
       "\n",
       "        [[0.2618, 0.2563, 0.2536,  ..., 0.2472, 0.2488, 0.2498],\n",
       "         [0.7382, 0.7437, 0.7464,  ..., 0.7528, 0.7512, 0.7502]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b711e209-865d-41e9-997d-e29463da7ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2, 60000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1be06f20-9509-4bb6-b41d-c4259f74840d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.3592],\n",
      "        [ 0.1598],\n",
      "        [-0.0487],\n",
      "        [ 0.2768],\n",
      "        [-0.1013],\n",
      "        [-0.0279],\n",
      "        [ 0.3813],\n",
      "        [ 0.3821],\n",
      "        [ 0.0834],\n",
      "        [-0.1654],\n",
      "        [-0.0716],\n",
      "        [ 0.0068],\n",
      "        [ 0.2304],\n",
      "        [ 0.2973],\n",
      "        [ 0.1545],\n",
      "        [ 0.4453],\n",
      "        [-0.1392],\n",
      "        [-0.0912],\n",
      "        [-0.2889],\n",
      "        [ 0.2885]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.2917],\n",
      "        [-0.3682],\n",
      "        [ 0.0993],\n",
      "        [-0.3259],\n",
      "        [ 0.4269],\n",
      "        [-0.2879],\n",
      "        [ 0.2091],\n",
      "        [ 0.3414],\n",
      "        [ 0.0187],\n",
      "        [-0.3138],\n",
      "        [-0.4030],\n",
      "        [ 0.0831],\n",
      "        [ 0.4470],\n",
      "        [-0.2244],\n",
      "        [ 0.3867],\n",
      "        [-0.1484],\n",
      "        [ 0.3284],\n",
      "        [ 0.1145],\n",
      "        [ 0.1456],\n",
      "        [-0.0074]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3175, -0.4095, -0.0558, -0.1720, -0.0978, -0.2054,  0.0591,  0.3505,\n",
      "         0.1288, -0.0831, -0.2292,  0.2767,  0.3148,  0.1410,  0.2174, -0.2993,\n",
      "        -0.1548, -0.1494, -0.3261, -0.1672], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2164, -0.3279, -0.2040, -0.3552,  0.1948, -0.3140, -0.3541, -0.3544,\n",
      "         0.3547,  0.3520, -0.3366,  0.4129, -0.0421, -0.1422,  0.1066, -0.1054,\n",
      "         0.2452, -0.4079,  0.4375,  0.2229], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.2333,  0.4121, -0.3205, -0.0045, -0.0831]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1578],\n",
      "        [-0.3395],\n",
      "        [ 0.3097],\n",
      "        [-0.1033],\n",
      "        [ 0.0707],\n",
      "        [ 0.1168],\n",
      "        [-0.1555],\n",
      "        [-0.1094],\n",
      "        [-0.1138],\n",
      "        [-0.2946],\n",
      "        [ 0.2158],\n",
      "        [-0.4110],\n",
      "        [-0.1083],\n",
      "        [ 0.2271],\n",
      "        [ 0.0389],\n",
      "        [ 0.3090],\n",
      "        [ 0.3213],\n",
      "        [-0.1659],\n",
      "        [-0.1582],\n",
      "        [-0.3474]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0525],\n",
      "        [-0.3582],\n",
      "        [-0.4009],\n",
      "        [ 0.0835],\n",
      "        [ 0.2231],\n",
      "        [-0.0812],\n",
      "        [-0.2026],\n",
      "        [ 0.1628],\n",
      "        [ 0.4046],\n",
      "        [ 0.4375],\n",
      "        [-0.3631],\n",
      "        [ 0.2050],\n",
      "        [-0.2403],\n",
      "        [ 0.0115],\n",
      "        [-0.3749],\n",
      "        [ 0.2703],\n",
      "        [ 0.1498],\n",
      "        [-0.0348],\n",
      "        [-0.3295],\n",
      "        [-0.1428]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3420,  0.2505,  0.2473, -0.3301, -0.2885, -0.4398, -0.4004,  0.2632,\n",
      "        -0.2607, -0.0810,  0.1974,  0.0732, -0.1513, -0.0280,  0.0501,  0.0298,\n",
      "        -0.0156, -0.4394,  0.1603, -0.1669], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1989, -0.0795, -0.3645, -0.0859,  0.2394, -0.4262, -0.2646, -0.3250,\n",
      "         0.1866, -0.0233,  0.1970, -0.3058, -0.0699, -0.1593, -0.1496,  0.1632,\n",
      "        -0.0958, -0.2822, -0.0978,  0.3233], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1930,  0.0129, -0.4261,  0.1262, -0.3890]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1765, -0.4188],\n",
      "        [ 0.0464, -0.2304],\n",
      "        [ 0.3079,  0.2508],\n",
      "        [ 0.2220,  0.1225],\n",
      "        [-0.2990,  0.1948],\n",
      "        [-0.4128, -0.3841],\n",
      "        [-0.2472, -0.1178],\n",
      "        [ 0.0491,  0.0682],\n",
      "        [ 0.4164, -0.3804],\n",
      "        [-0.1020,  0.1621],\n",
      "        [ 0.2901, -0.1698],\n",
      "        [-0.3658, -0.3382],\n",
      "        [ 0.3353,  0.1975],\n",
      "        [-0.2300, -0.0559],\n",
      "        [-0.3227,  0.3158],\n",
      "        [-0.1441, -0.4191],\n",
      "        [-0.0808,  0.2011],\n",
      "        [-0.1013,  0.0607],\n",
      "        [ 0.0795,  0.2867],\n",
      "        [ 0.4212, -0.1826]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0591],\n",
      "        [ 0.1646],\n",
      "        [ 0.0051],\n",
      "        [-0.0511],\n",
      "        [-0.4382],\n",
      "        [-0.3554],\n",
      "        [-0.1388],\n",
      "        [-0.3573],\n",
      "        [ 0.1529],\n",
      "        [ 0.3299],\n",
      "        [-0.0977],\n",
      "        [-0.2737],\n",
      "        [ 0.0857],\n",
      "        [ 0.2704],\n",
      "        [ 0.4287],\n",
      "        [ 0.1655],\n",
      "        [ 0.3655],\n",
      "        [ 0.1530],\n",
      "        [ 0.0669],\n",
      "        [ 0.4234]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0517,  0.4306, -0.2703,  0.0651,  0.2783, -0.2477, -0.1630,  0.3414,\n",
      "        -0.1616, -0.4118,  0.0684, -0.1532, -0.2412, -0.3053,  0.2644, -0.1168,\n",
      "        -0.0169, -0.1562, -0.1121, -0.2223], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0967, -0.0740,  0.3605,  0.3896, -0.1326, -0.3273,  0.4194,  0.2322,\n",
      "        -0.1158,  0.3537,  0.2366,  0.3627, -0.0524,  0.1446,  0.2147, -0.2746,\n",
      "         0.1895, -0.2497, -0.1202,  0.2575], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1754, -0.1857,  0.2235,  0.0586,  0.0509]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0578, -0.3483],\n",
      "        [-0.1722, -0.3168],\n",
      "        [ 0.2961,  0.1688],\n",
      "        [ 0.2934, -0.3027],\n",
      "        [-0.2853,  0.1948],\n",
      "        [-0.4147, -0.0059],\n",
      "        [-0.0806,  0.3821],\n",
      "        [-0.0025,  0.4257],\n",
      "        [-0.4119,  0.3070],\n",
      "        [-0.4464,  0.0075],\n",
      "        [-0.0486, -0.1119],\n",
      "        [-0.2734, -0.3139],\n",
      "        [-0.1152,  0.2557],\n",
      "        [ 0.4022,  0.1408],\n",
      "        [ 0.1568, -0.1770],\n",
      "        [ 0.1306, -0.0232],\n",
      "        [-0.3209, -0.3073],\n",
      "        [-0.4071,  0.1613],\n",
      "        [-0.3139,  0.2441],\n",
      "        [-0.2524, -0.1934]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1283],\n",
      "        [ 0.1508],\n",
      "        [-0.4092],\n",
      "        [ 0.3391],\n",
      "        [-0.3109],\n",
      "        [ 0.1677],\n",
      "        [ 0.0643],\n",
      "        [ 0.3269],\n",
      "        [-0.1369],\n",
      "        [ 0.2044],\n",
      "        [ 0.3100],\n",
      "        [-0.4183],\n",
      "        [ 0.0381],\n",
      "        [-0.0186],\n",
      "        [ 0.0434],\n",
      "        [-0.0667],\n",
      "        [-0.0809],\n",
      "        [ 0.3521],\n",
      "        [ 0.2186],\n",
      "        [-0.1114]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0119, -0.2395, -0.3793,  0.0987, -0.3607, -0.3828,  0.1669, -0.3448,\n",
      "        -0.0016, -0.2971, -0.3542, -0.1806,  0.3789,  0.0655, -0.4035, -0.1230,\n",
      "        -0.1220, -0.2542,  0.2069,  0.1115], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1328, -0.0576, -0.1253,  0.4346,  0.2782, -0.4277, -0.2062,  0.4170,\n",
      "         0.1845, -0.4425,  0.3405,  0.3190,  0.2369,  0.0798, -0.3789, -0.2921,\n",
      "         0.2324, -0.4185, -0.0098,  0.3389], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0210, -0.2150,  0.2163, -0.3163, -0.1099]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in model.parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d3fcc13-92ca-4653-a4bf-a906f669e187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('lstm.weight_ih_l0',\n",
       "              tensor([[ 9.5604e-01],\n",
       "                      [-2.7282e-01],\n",
       "                      [-6.0851e-01],\n",
       "                      [-7.6993e-01],\n",
       "                      [ 1.1170e+00],\n",
       "                      [ 9.4927e-01],\n",
       "                      [ 1.4081e+00],\n",
       "                      [ 7.1743e-01],\n",
       "                      [ 2.6803e-01],\n",
       "                      [ 8.7604e-01],\n",
       "                      [-1.5671e-03],\n",
       "                      [ 9.5805e-01],\n",
       "                      [ 1.7373e+00],\n",
       "                      [ 5.7856e-01],\n",
       "                      [ 1.9273e-01],\n",
       "                      [-3.7190e-01],\n",
       "                      [ 1.2352e+00],\n",
       "                      [ 1.0384e+00],\n",
       "                      [-7.7336e-01],\n",
       "                      [-3.9639e-01]])),\n",
       "             ('lstm.weight_hh_l0',\n",
       "              tensor([[-0.0127],\n",
       "                      [-0.5819],\n",
       "                      [ 0.4052],\n",
       "                      [-0.2645],\n",
       "                      [ 0.5958],\n",
       "                      [ 1.3224],\n",
       "                      [ 1.0717],\n",
       "                      [ 1.0647],\n",
       "                      [-0.5226],\n",
       "                      [ 0.4872],\n",
       "                      [-0.3870],\n",
       "                      [-0.1755],\n",
       "                      [ 0.2668],\n",
       "                      [-0.6935],\n",
       "                      [-0.4310],\n",
       "                      [ 1.6073],\n",
       "                      [ 1.3843],\n",
       "                      [ 0.9479],\n",
       "                      [-0.4458],\n",
       "                      [ 1.7140]])),\n",
       "             ('lstm.bias_ih_l0',\n",
       "              tensor([-0.0204,  0.1013, -1.0839, -0.2285,  0.5610,  1.2406,  0.3476, -0.2490,\n",
       "                      -0.2261,  0.3147, -0.3567,  0.4200, -0.1351, -0.2050, -0.7695, -0.1376,\n",
       "                      -0.5339, -0.7854, -0.4354,  0.3343])),\n",
       "             ('lstm.bias_hh_l0',\n",
       "              tensor([-0.0556, -0.4213, -0.3166, -0.0079,  1.0107,  0.6574,  0.5611,  0.0418,\n",
       "                       0.4927,  0.4262, -0.9251,  0.1441,  0.0217, -0.5992, -0.8060,  0.2038,\n",
       "                      -0.5677, -1.0124,  0.1348,  0.4868])),\n",
       "             ('lstm.weight_hr_l0',\n",
       "              tensor([[-0.6594,  1.6689,  0.6340,  0.3395, -1.0574]])),\n",
       "             ('lstm.weight_ih_l0_reverse',\n",
       "              tensor([[ 0.6456],\n",
       "                      [ 0.6650],\n",
       "                      [ 0.2553],\n",
       "                      [ 1.3184],\n",
       "                      [-0.4232],\n",
       "                      [-0.8919],\n",
       "                      [-0.7127],\n",
       "                      [ 0.6647],\n",
       "                      [-0.5699],\n",
       "                      [-0.3976],\n",
       "                      [-1.1938],\n",
       "                      [-0.4469],\n",
       "                      [-0.8871],\n",
       "                      [-0.2134],\n",
       "                      [-1.2958],\n",
       "                      [-0.5859],\n",
       "                      [-0.9584],\n",
       "                      [ 0.5818],\n",
       "                      [ 1.2495],\n",
       "                      [-0.3058]])),\n",
       "             ('lstm.weight_hh_l0_reverse',\n",
       "              tensor([[ 0.7401],\n",
       "                      [ 0.8379],\n",
       "                      [ 2.5354],\n",
       "                      [ 0.6404],\n",
       "                      [ 0.6336],\n",
       "                      [-0.1150],\n",
       "                      [-0.1017],\n",
       "                      [ 1.3572],\n",
       "                      [ 2.3918],\n",
       "                      [ 0.0406],\n",
       "                      [ 1.6879],\n",
       "                      [ 2.6965],\n",
       "                      [-1.0014],\n",
       "                      [ 2.4753],\n",
       "                      [-2.9329],\n",
       "                      [-1.2580],\n",
       "                      [-0.5926],\n",
       "                      [ 1.7712],\n",
       "                      [ 0.9152],\n",
       "                      [ 0.4595]])),\n",
       "             ('lstm.bias_ih_l0_reverse',\n",
       "              tensor([ 0.2049, -0.0904, -0.7607,  0.7262, -0.7340,  1.5245,  2.3120,  0.9988,\n",
       "                       1.5919, -0.3861, -0.6585,  0.2314, -1.1859,  0.4462,  0.4516,  1.7487,\n",
       "                       1.6387,  1.2146,  1.5279, -0.0625])),\n",
       "             ('lstm.bias_hh_l0_reverse',\n",
       "              tensor([-0.0794,  0.2130, -0.9343,  0.6201, -0.8695,  1.9244,  2.3389,  1.3939,\n",
       "                       1.6819, -0.4755,  0.0613, -0.1721, -0.7902,  0.2510,  0.8149,  1.2810,\n",
       "                       2.0542,  1.2195,  1.3246, -0.3276])),\n",
       "             ('lstm.weight_hr_l0_reverse',\n",
       "              tensor([[ 1.5665,  1.8515, -0.2700,  1.5150, -0.7513]])),\n",
       "             ('lstm.weight_ih_l1',\n",
       "              tensor([[ 1.4456e+00,  1.6030e+00],\n",
       "                      [-2.4169e-01,  1.6053e+00],\n",
       "                      [ 4.7337e-01,  1.0955e+00],\n",
       "                      [-1.2362e-01,  1.2667e+00],\n",
       "                      [ 2.4161e+00,  5.3808e-01],\n",
       "                      [-1.8692e-01,  4.0674e+00],\n",
       "                      [-7.1603e-02,  1.4511e+00],\n",
       "                      [ 6.3979e-01,  1.3188e+00],\n",
       "                      [-4.5362e-01,  1.0678e+00],\n",
       "                      [ 2.9250e+00, -1.1072e-01],\n",
       "                      [-9.4606e-01, -1.1712e+00],\n",
       "                      [ 1.0741e-01, -8.8121e-01],\n",
       "                      [-6.6315e-01, -8.0813e-01],\n",
       "                      [-8.1288e-01, -6.8462e-01],\n",
       "                      [-9.1719e-02, -8.1482e-01],\n",
       "                      [ 1.9653e-04,  5.0454e-01],\n",
       "                      [-9.2762e-01,  1.5947e+00],\n",
       "                      [ 8.4840e-02,  1.1563e+00],\n",
       "                      [-4.6815e-01,  1.3604e+00],\n",
       "                      [ 3.1611e+00, -1.9491e+00]])),\n",
       "             ('lstm.weight_hh_l1',\n",
       "              tensor([[-1.2721],\n",
       "                      [ 0.1126],\n",
       "                      [ 0.1910],\n",
       "                      [-0.4831],\n",
       "                      [-0.4869],\n",
       "                      [ 0.3330],\n",
       "                      [ 0.2507],\n",
       "                      [ 0.6062],\n",
       "                      [-0.7391],\n",
       "                      [-0.2382],\n",
       "                      [-0.6032],\n",
       "                      [ 0.9732],\n",
       "                      [ 0.4333],\n",
       "                      [ 0.2459],\n",
       "                      [ 1.3823],\n",
       "                      [ 0.3352],\n",
       "                      [-0.1738],\n",
       "                      [-0.3097],\n",
       "                      [-0.2188],\n",
       "                      [-1.5860]])),\n",
       "             ('lstm.bias_ih_l1',\n",
       "              tensor([-0.5972, -0.5041, -0.1432, -0.4131, -1.7268,  1.6587,  0.7260,  0.0840,\n",
       "                       0.1682, -1.5427,  0.8761,  0.2291, -0.3047, -0.0248,  0.8616,  0.5428,\n",
       "                      -0.0447, -0.2648, -0.0027,  1.0665])),\n",
       "             ('lstm.bias_hh_l1',\n",
       "              tensor([-0.7093, -0.5958, -0.2603, -0.0864, -1.3785,  1.3349, -0.0024,  0.1583,\n",
       "                      -0.3487, -1.7396,  0.1117,  0.2908, -0.1619, -0.0621,  0.5455,  0.7633,\n",
       "                       0.1690, -0.0190,  0.0149,  1.1671])),\n",
       "             ('lstm.weight_hr_l1',\n",
       "              tensor([[ 0.6171, -0.2655, -0.2091, -0.3290,  1.2100]])),\n",
       "             ('lstm.weight_ih_l1_reverse',\n",
       "              tensor([[ 0.1053,  1.0883],\n",
       "                      [-2.0509,  1.3577],\n",
       "                      [-0.0353, -1.2583],\n",
       "                      [-0.5656,  0.7656],\n",
       "                      [-0.4836, -0.9757],\n",
       "                      [ 0.2020,  0.6441],\n",
       "                      [-0.7879,  1.6908],\n",
       "                      [ 0.7743, -1.1265],\n",
       "                      [-0.0296,  1.7232],\n",
       "                      [ 0.2844,  2.4034],\n",
       "                      [-0.2911,  0.8066],\n",
       "                      [-0.0243,  0.9547],\n",
       "                      [-0.2002,  0.9184],\n",
       "                      [-0.3733, -0.2351],\n",
       "                      [ 0.6850,  0.3364],\n",
       "                      [ 0.1620,  0.6620],\n",
       "                      [-1.2681,  1.2889],\n",
       "                      [ 0.2320,  1.5374],\n",
       "                      [-0.9892,  1.5637],\n",
       "                      [-3.3855,  2.1968]])),\n",
       "             ('lstm.weight_hh_l1_reverse',\n",
       "              tensor([[-0.1524],\n",
       "                      [ 0.8377],\n",
       "                      [ 0.5185],\n",
       "                      [-0.3010],\n",
       "                      [ 0.2421],\n",
       "                      [-0.0561],\n",
       "                      [ 0.5064],\n",
       "                      [-0.6151],\n",
       "                      [-0.2640],\n",
       "                      [ 0.1419],\n",
       "                      [ 0.1229],\n",
       "                      [ 0.1286],\n",
       "                      [-0.3145],\n",
       "                      [-0.9674],\n",
       "                      [ 0.7087],\n",
       "                      [ 0.7453],\n",
       "                      [-0.0869],\n",
       "                      [ 1.2620],\n",
       "                      [-0.3598],\n",
       "                      [ 0.6219]])),\n",
       "             ('lstm.bias_ih_l1_reverse',\n",
       "              tensor([-0.0833, -0.4473,  0.4745,  0.5179,  0.4354, -0.0991,  0.6309,  0.3316,\n",
       "                       0.5075,  1.9165,  0.0290, -0.6797, -0.6267,  0.2443,  0.0379, -0.4601,\n",
       "                      -0.0646, -1.1910, -0.2440,  0.5055])),\n",
       "             ('lstm.bias_hh_l1_reverse',\n",
       "              tensor([-0.6769, -0.1687,  0.5897,  0.5446,  0.7002, -0.5158,  1.1579,  0.5703,\n",
       "                       1.0688,  1.4581,  0.0180, -0.0496, -0.2786,  0.3107, -0.3797, -0.0195,\n",
       "                       0.5004, -1.2978,  0.0443,  0.2398])),\n",
       "             ('lstm.weight_hr_l1_reverse',\n",
       "              tensor([[ 0.3930,  0.3039, -0.6739, -0.5025,  0.5947]]))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.load(f\"C:/Users/Marc/Desktop/network/network_LSTM-510.pt\", map_location='cpu')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f1f15d-3f4d-4158-a803-66df33db6521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9fd6e37-8802-4daa-8e2e-73f1109affcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_net(\n",
       "  (lstm): LSTM(1, 5, proj_size=1, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (soft): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "device = \"cpu\"\n",
    "\n",
    "model = LSTM_net(batch_size=batch_size, device=device).to(device)\n",
    "x = torch.load(f\"C:/Users/Marc/Desktop/network/network_LSTM-510.pt\", map_location='cpu')\n",
    "model.load_state_dict(x)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8919f87-8605-48a6-9a94-5e063b80b39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ea66e2f-88c9-4575-a122-4f4816064ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2765, 0.3258, 0.5128,  ..., 0.7003, 0.4630, 0.0561],\n",
       "         [0.7235, 0.6742, 0.4872,  ..., 0.2997, 0.5370, 0.9439]],\n",
       "\n",
       "        [[0.2805, 0.3000, 0.3256,  ..., 0.5105, 0.5104, 0.5063],\n",
       "         [0.7195, 0.7000, 0.6744,  ..., 0.4895, 0.4896, 0.4937]],\n",
       "\n",
       "        [[0.2710, 0.2571, 0.2620,  ..., 0.0217, 0.0906, 0.1333],\n",
       "         [0.7290, 0.7429, 0.7380,  ..., 0.9783, 0.9094, 0.8667]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.2699, 0.2731, 0.1088,  ..., 0.1321, 0.1606, 0.1901],\n",
       "         [0.7301, 0.7269, 0.8912,  ..., 0.8679, 0.8394, 0.8099]],\n",
       "\n",
       "        [[0.2090, 0.2195, 0.2205,  ..., 0.0412, 0.0566, 0.0761],\n",
       "         [0.7910, 0.7805, 0.7795,  ..., 0.9588, 0.9434, 0.9239]],\n",
       "\n",
       "        [[0.2820, 0.3570, 0.6185,  ..., 0.2710, 0.2696, 0.0930],\n",
       "         [0.7180, 0.6430, 0.3815,  ..., 0.7290, 0.7304, 0.9070]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6873ce-8044-4a4d-9f42-139fe1c50cca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f23491-f2b7-486d-a32b-cfbed21bd997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c261c77-16fe-40f9-b003-975c6a69e8e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_net(\n",
       "  (lstm): LSTM(1, 5, proj_size=1, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (soft): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 1\n",
    "device = \"cpu\"\n",
    "\n",
    "model = LSTM_net(batch_size=batch_size, device=device).to(device)\n",
    "x = torch.load(f\"C:/Users/Marc/Desktop/network/network_LSTM-510.pt\", map_location='cpu')\n",
    "model.load_state_dict(x)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4923299c-a9cc-4c6e-955b-4d63fbfa8bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2765, 0.3258, 0.5128,  ..., 0.7003, 0.4630, 0.0561],\n",
       "         [0.7235, 0.6742, 0.4872,  ..., 0.2997, 0.5370, 0.9439]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(ind[0].view(1, 1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d55f72f6-86d5-4913-b627-9ffe17b3ec47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2820, 0.3570, 0.6185,  ..., 0.2710, 0.2696, 0.0930],\n",
       "         [0.7180, 0.6430, 0.3815,  ..., 0.7290, 0.7304, 0.9070]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(ind[9].view(1, 1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22991767-e866-4aec-9245-ea8ea4cb1ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0589888-fa86-42c9-b72f-6ead296dbe31",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for LSTM_net:\n\tUnexpected key(s) in state_dict: \"lstm.weight_ih_l2\", \"lstm.weight_hh_l2\", \"lstm.bias_ih_l2\", \"lstm.bias_hh_l2\", \"lstm.weight_hr_l2\", \"lstm.weight_ih_l2_reverse\", \"lstm.weight_hh_l2_reverse\", \"lstm.bias_ih_l2_reverse\", \"lstm.bias_hh_l2_reverse\", \"lstm.weight_hr_l2_reverse\", \"lstm.weight_ih_l3\", \"lstm.weight_hh_l3\", \"lstm.bias_ih_l3\", \"lstm.bias_hh_l3\", \"lstm.weight_hr_l3\", \"lstm.weight_ih_l3_reverse\", \"lstm.weight_hh_l3_reverse\", \"lstm.bias_ih_l3_reverse\", \"lstm.bias_hh_l3_reverse\", \"lstm.weight_hr_l3_reverse\", \"lstm.weight_ih_l4\", \"lstm.weight_hh_l4\", \"lstm.bias_ih_l4\", \"lstm.bias_hh_l4\", \"lstm.weight_hr_l4\", \"lstm.weight_ih_l4_reverse\", \"lstm.weight_hh_l4_reverse\", \"lstm.bias_ih_l4_reverse\", \"lstm.bias_hh_l4_reverse\", \"lstm.weight_hr_l4_reverse\". \n\tsize mismatch for lstm.weight_ih_l0: copying a param with shape torch.Size([8, 1]) from checkpoint, the shape in current model is torch.Size([20, 1]).\n\tsize mismatch for lstm.weight_hh_l0: copying a param with shape torch.Size([8, 1]) from checkpoint, the shape in current model is torch.Size([20, 1]).\n\tsize mismatch for lstm.bias_ih_l0: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for lstm.bias_hh_l0: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for lstm.weight_hr_l0: copying a param with shape torch.Size([1, 2]) from checkpoint, the shape in current model is torch.Size([1, 5]).\n\tsize mismatch for lstm.weight_ih_l0_reverse: copying a param with shape torch.Size([8, 1]) from checkpoint, the shape in current model is torch.Size([20, 1]).\n\tsize mismatch for lstm.weight_hh_l0_reverse: copying a param with shape torch.Size([8, 1]) from checkpoint, the shape in current model is torch.Size([20, 1]).\n\tsize mismatch for lstm.bias_ih_l0_reverse: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for lstm.bias_hh_l0_reverse: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for lstm.weight_hr_l0_reverse: copying a param with shape torch.Size([1, 2]) from checkpoint, the shape in current model is torch.Size([1, 5]).\n\tsize mismatch for lstm.weight_ih_l1: copying a param with shape torch.Size([8, 2]) from checkpoint, the shape in current model is torch.Size([20, 2]).\n\tsize mismatch for lstm.weight_hh_l1: copying a param with shape torch.Size([8, 1]) from checkpoint, the shape in current model is torch.Size([20, 1]).\n\tsize mismatch for lstm.bias_ih_l1: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for lstm.bias_hh_l1: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for lstm.weight_hr_l1: copying a param with shape torch.Size([1, 2]) from checkpoint, the shape in current model is torch.Size([1, 5]).\n\tsize mismatch for lstm.weight_ih_l1_reverse: copying a param with shape torch.Size([8, 2]) from checkpoint, the shape in current model is torch.Size([20, 2]).\n\tsize mismatch for lstm.weight_hh_l1_reverse: copying a param with shape torch.Size([8, 1]) from checkpoint, the shape in current model is torch.Size([20, 1]).\n\tsize mismatch for lstm.bias_ih_l1_reverse: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for lstm.bias_hh_l1_reverse: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for lstm.weight_hr_l1_reverse: copying a param with shape torch.Size([1, 2]) from checkpoint, the shape in current model is torch.Size([1, 5]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m LSTM_net(batch_size\u001b[38;5;241m=\u001b[39mbatch_size, device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      6\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMarc\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mWierd output\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mnet.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deep\\lib\\site-packages\\torch\\nn\\modules\\module.py:1497\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1492\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   1493\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1494\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1497\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1498\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for LSTM_net:\n\tUnexpected key(s) in state_dict: \"lstm.weight_ih_l2\", \"lstm.weight_hh_l2\", \"lstm.bias_ih_l2\", \"lstm.bias_hh_l2\", \"lstm.weight_hr_l2\", \"lstm.weight_ih_l2_reverse\", \"lstm.weight_hh_l2_reverse\", \"lstm.bias_ih_l2_reverse\", \"lstm.bias_hh_l2_reverse\", \"lstm.weight_hr_l2_reverse\", \"lstm.weight_ih_l3\", \"lstm.weight_hh_l3\", \"lstm.bias_ih_l3\", \"lstm.bias_hh_l3\", \"lstm.weight_hr_l3\", \"lstm.weight_ih_l3_reverse\", \"lstm.weight_hh_l3_reverse\", \"lstm.bias_ih_l3_reverse\", \"lstm.bias_hh_l3_reverse\", \"lstm.weight_hr_l3_reverse\", \"lstm.weight_ih_l4\", \"lstm.weight_hh_l4\", \"lstm.bias_ih_l4\", \"lstm.bias_hh_l4\", \"lstm.weight_hr_l4\", \"lstm.weight_ih_l4_reverse\", \"lstm.weight_hh_l4_reverse\", \"lstm.bias_ih_l4_reverse\", \"lstm.bias_hh_l4_reverse\", \"lstm.weight_hr_l4_reverse\". \n\tsize mismatch for lstm.weight_ih_l0: copying a param with shape torch.Size([8, 1]) from checkpoint, the shape in current model is torch.Size([20, 1]).\n\tsize mismatch for lstm.weight_hh_l0: copying a param with shape torch.Size([8, 1]) from checkpoint, the shape in current model is torch.Size([20, 1]).\n\tsize mismatch for lstm.bias_ih_l0: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for lstm.bias_hh_l0: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for lstm.weight_hr_l0: copying a param with shape torch.Size([1, 2]) from checkpoint, the shape in current model is torch.Size([1, 5]).\n\tsize mismatch for lstm.weight_ih_l0_reverse: copying a param with shape torch.Size([8, 1]) from checkpoint, the shape in current model is torch.Size([20, 1]).\n\tsize mismatch for lstm.weight_hh_l0_reverse: copying a param with shape torch.Size([8, 1]) from checkpoint, the shape in current model is torch.Size([20, 1]).\n\tsize mismatch for lstm.bias_ih_l0_reverse: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for lstm.bias_hh_l0_reverse: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for lstm.weight_hr_l0_reverse: copying a param with shape torch.Size([1, 2]) from checkpoint, the shape in current model is torch.Size([1, 5]).\n\tsize mismatch for lstm.weight_ih_l1: copying a param with shape torch.Size([8, 2]) from checkpoint, the shape in current model is torch.Size([20, 2]).\n\tsize mismatch for lstm.weight_hh_l1: copying a param with shape torch.Size([8, 1]) from checkpoint, the shape in current model is torch.Size([20, 1]).\n\tsize mismatch for lstm.bias_ih_l1: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for lstm.bias_hh_l1: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for lstm.weight_hr_l1: copying a param with shape torch.Size([1, 2]) from checkpoint, the shape in current model is torch.Size([1, 5]).\n\tsize mismatch for lstm.weight_ih_l1_reverse: copying a param with shape torch.Size([8, 2]) from checkpoint, the shape in current model is torch.Size([20, 2]).\n\tsize mismatch for lstm.weight_hh_l1_reverse: copying a param with shape torch.Size([8, 1]) from checkpoint, the shape in current model is torch.Size([20, 1]).\n\tsize mismatch for lstm.bias_ih_l1_reverse: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for lstm.bias_hh_l1_reverse: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for lstm.weight_hr_l1_reverse: copying a param with shape torch.Size([1, 2]) from checkpoint, the shape in current model is torch.Size([1, 5])."
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "device = \"cpu\"\n",
    "\n",
    "model = LSTM_net(batch_size=batch_size, device=device).to(device)\n",
    "\n",
    "x = torch.load(r\"C:\\Users\\Marc\\Desktop\\Wierd output\\net.pt\", map_location='cpu')\n",
    "model.load_state_dict(x)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c385a70-c5dc-4069-8062-043845a00d51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8888c47-60f9-44f9-a37e-2f4daeb82179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f03d686-8e9c-4aa0-8f53-62e440dc510a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0e6548-fc9c-42d8-bc3b-e1de4f5a5754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e412eb-f23e-46bd-8357-d0a4cc1295f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(ind[0].view(1, 1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3821d788-999a-4510-ad63-ba38e599cbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7567b2-ed9c-48b6-a71e-a7fb7fc5658c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd3bd8c-2715-4de8-bf1b-8bf450067a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in model.parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bdaff7-b498-4e58-a4b1-9fd91022556e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1c6d9a-f8ed-4225-9cfd-7d095163140b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0308990f-f107-4cdf-81b3-d16c3c8f78df",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "device = \"cpu\"\n",
    "\n",
    "model = LSTM_net(batch_size=batch_size, device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1c6a6e-d44d-4606-a00d-befd689a11f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind[0].view(1, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78287bcc-2bce-4895-9105-d0d1e0cada78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(ind[0].view(1, 1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58cd67b-ddac-49e1-8b63-526ea5f0f23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(ind[1].view(1, 1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325d60e1-b238-4e9b-b7b0-99a5540b5a93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
