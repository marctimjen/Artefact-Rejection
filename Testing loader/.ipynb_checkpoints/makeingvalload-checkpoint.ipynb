{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74ba597f-563e-4f13-81f8-fbb10088d21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a32b280f-1e78-46d8-99fd-0a97c50b02df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class rando(Dataset):\n",
    "    \"\"\"\n",
    "    This dataloader loads random 5 minute intervals from a random patient.\n",
    "    \"\"\"\n",
    "    def __init__(self, ls_len, seed = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            path (str): path to the input & target folder.\n",
    "            series_dict (list): name of dict for data.\n",
    "            size : (number of experiments, number of max. channels, longest series)\n",
    "            device (class 'torch.device'): which pytorch device the data should\n",
    "            be sent to.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        self.length = ls_len\n",
    "        self.seed = seed\n",
    "        \n",
    "        if not(seed):\n",
    "            self.rng = np.random.default_rng(self.seed)\n",
    "            self.gen = iter(self.create_data(self.rng))\n",
    "        \n",
    "\n",
    "    def create_data(self, rng):\n",
    "        while True:\n",
    "            ind = rng.choice(10, 1)\n",
    "            yield ind\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.seed:\n",
    "            if idx == 0:\n",
    "                self.rng = np.random.default_rng(self.seed)\n",
    "                self.gen = iter(self.create_data(self.rng))\n",
    "            \n",
    "            \n",
    "        tal = next(self.gen)\n",
    "        return tal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "201d6c2e-f1c7-4656-b39c-3e82139baa99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2],\n",
      "        [9],\n",
      "        [3]])\n",
      "tensor([[5],\n",
      "        [4],\n",
      "        [4]])\n",
      "\n",
      "tensor([[4],\n",
      "        [5],\n",
      "        [7],\n",
      "        [9],\n",
      "        [0]])\n",
      "tensor([[1],\n",
      "        [8],\n",
      "        [9],\n",
      "        [2],\n",
      "        [3]])\n",
      "\n",
      "tensor([[0],\n",
      "        [1],\n",
      "        [5]])\n",
      "tensor([[3],\n",
      "        [3],\n",
      "        [4]])\n",
      "\n",
      "tensor([[4],\n",
      "        [5],\n",
      "        [7],\n",
      "        [9],\n",
      "        [0]])\n",
      "tensor([[1],\n",
      "        [8],\n",
      "        [9],\n",
      "        [2],\n",
      "        [3]])\n"
     ]
    }
   ],
   "source": [
    "train_file = rando(ls_len = 6)\n",
    "train_load = torch.utils.data.DataLoader(train_file,\n",
    "                                           batch_size=3,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=0)\n",
    "\n",
    "val_file = rando(ls_len = 10, seed = 1)\n",
    "val_loader = torch.utils.data.DataLoader(val_file,\n",
    "                                           batch_size=5,\n",
    "                                           shuffle=False,\n",
    "                                           num_workers=0)\n",
    "\n",
    "for i in train_load:\n",
    "    print(i)\n",
    "\n",
    "print()\n",
    "    \n",
    "for i in val_loader:\n",
    "    print(i)\n",
    "    \n",
    "print()\n",
    "    \n",
    "for i in train_load:\n",
    "    print(i)\n",
    "\n",
    "print()\n",
    "\n",
    "for i in val_loader:\n",
    "    print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1b5a90a9-e623-4092-9b83-8021e640e8f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9 % (10-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "61b6af7d-8023-4c0e-9087-8196a4b0560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class shuffle_5min(Dataset):\n",
    "    \"\"\"\n",
    "    This dataloader loads random 5 minute intervals from a random patient.\n",
    "    \"\"\"\n",
    "    def __init__(self, path: str, series_dict: str, size: tuple, device, seed = None, length = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            path (str): path to the input & target folder.\n",
    "            series_dict (list): name of dict for data.\n",
    "            size : (number of experiments, number of max. channels, longest series)\n",
    "            device (class 'torch.device'): which pytorch device the data should\n",
    "            be sent to.\n",
    "        \"\"\"\n",
    "\n",
    "        self.device = device\n",
    "        self.size = size\n",
    "        self.path = path\n",
    "        self.seed = seed\n",
    "        \n",
    "        with open(path + \"/\" + series_dict, 'rb') as handle:\n",
    "            self.s_dict = pickle.load(handle)\n",
    "\n",
    "        self.input_data = np.memmap(self.path + \"/model_input.dat\", dtype='float32', mode='r', shape=self.size)\n",
    "        self.target_data = np.memmap(self.path + \"/model_target.dat\", dtype='float32', mode='r', shape=self.size)\n",
    "\n",
    "        prop = [] # list with probabilities\n",
    "\n",
    "        ss = 0 # sum over all the batches\n",
    "        for val in self.s_dict.values():\n",
    "            prop.append(val[2])\n",
    "            ss += val[2]\n",
    "\n",
    "        self.prop = np.array(prop) / ss\n",
    "        \n",
    "        if length:\n",
    "            self.length = length\n",
    "        else:\n",
    "            self.length = ss\n",
    "\n",
    "        \n",
    "        if not(seed):\n",
    "            self.rng = np.random.default_rng(self.seed)\n",
    "            self.gen = iter(self.create_data(self.s_dict, self.rng))\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def create_data(self, s_dict, rng):\n",
    "        while True:\n",
    "            ind = rng.choice(self.size[0], 1, p = self.prop)\n",
    "            shp = s_dict[ind[0] + 1][3] # shape of experiment\n",
    "\n",
    "            cut_point = rng.integers(low = 200*30, #remove the first 30 secs\n",
    "                                high = shp[1] - 5*200*60, size = 1)\n",
    "                                # choose the place to cut\n",
    "\n",
    "            chan = rng.choice(shp[0], 1)\n",
    "\n",
    "            inp = self.input_data[ind[0], chan[0], cut_point[0]:cut_point[0]+60*5*200]\n",
    "            inp = torch.tensor(inp).view(1, 60*5*200)\n",
    "            tar = self.target_data[ind[0], chan[0], cut_point[0]:cut_point[0]+60*5*200]\n",
    "            tar = torch.tensor(tar).view(1, 60*5*200)\n",
    "            # #inp = self.ls[0][0][chan][cut_point[i]:cut_point[i]+60*5*200]\n",
    "            # #tar = self.ls[1][0][chan][cut_point[i]:cut_point[i]+60*5*200]\n",
    "\n",
    "            #tar = torch.cat((tar[0], -1*(tar[0] - 1))).view(2, 60*5*200)\n",
    "            yield inp, tar, (ind[0], chan[0], cut_point[0])\n",
    "\n",
    "\n",
    "    def clear_ram(self, index):\n",
    "        \"\"\"\n",
    "        This function is for clearing the ram.\n",
    "        \"\"\"\n",
    "        if index % 1000 == 0:\n",
    "            del self.input_data\n",
    "            del self.target_data\n",
    "            self.input_data = np.memmap(self.path + \"/model_input.dat\", dtype='float32', mode='r', shape=self.size)\n",
    "            self.target_data = np.memmap(self.path + \"/model_target.dat\", dtype='float32', mode='r', shape=self.size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.seed:\n",
    "            if idx == 0:\n",
    "                self.rng = np.random.default_rng(self.seed)\n",
    "                self.gen = iter(self.create_data(self.s_dict, self.rng))\n",
    "        \n",
    "        inp, tar, chan = next(self.gen)\n",
    "        inp = inp.to(self.device)\n",
    "        tar = tar.to(self.device)\n",
    "        self.clear_ram(idx)\n",
    "        return inp, tar, chan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "eecf920d-1a05-48ce-97ab-db875f9e1d63",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19432/839248483.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m                                      \u001b[0mseries_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'train_series_length.pickle'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                                      \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m195\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m22\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2060000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                                      device = device)\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "\n",
    "train_path = \"C:/Users/Marc/Desktop/model_data/train_model_data\"\n",
    "val_path = \"C:/Users/Marc/Desktop/model_data/val_model_data\"\n",
    "\n",
    "train_load_file = shuffle_5min(path = train_path,\n",
    "                                     series_dict = 'train_series_length.pickle',\n",
    "                                     size = (195, 22, 2060000),\n",
    "                                     device = device)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_load_file,\n",
    "                                                batch_size=batch_size,\n",
    "                                                shuffle=True,\n",
    "                                                num_workers=0)\n",
    "\n",
    "val_load_file = shuffle_5min(path = val_path,\n",
    "                                     series_dict = 'val_series_length.pickle',\n",
    "                                     size = (28, 22, 549200),\n",
    "                                     device = device)\n",
    "\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_load_file,\n",
    "                                                batch_size=batch_size,\n",
    "                                                shuffle=True,\n",
    "                                                num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "0f5bbf82-3459-40b5-bbde-b413ca60f2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "[1]\n",
      "[4]\n",
      "[2]\n",
      "[0]\n",
      "[6]\n",
      "\n",
      "[2]\n",
      "[1]\n",
      "[4]\n",
      "[2]\n",
      "[0]\n",
      "[6]\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "\n",
    "print(rng.choice(3, 1, p = [0, 0.5, 0.5]))\n",
    "print(rng.integers(low = 0, high = 3, size = 1))\n",
    "print(rng.choice(10, 1))\n",
    "\n",
    "print(rng.choice(3, 1, p = [0, 0.5, 0.5]))\n",
    "print(rng.integers(low = 0, high = 3, size = 1))\n",
    "print(rng.choice(10, 1))\n",
    "\n",
    "print()\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "print(rng.choice(3, 1, p = [0, 0.5, 0.5]))\n",
    "print(rng.integers(low = 0, high = 3, size = 1))\n",
    "print(rng.choice(10, 1))\n",
    "\n",
    "print(rng.choice(3, 1, p = [0, 0.5, 0.5]))\n",
    "print(rng.integers(low = 0, high = 3, size = 1))\n",
    "print(rng.choice(10, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae337b4e-1f9f-4248-a053-100efac44bad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
