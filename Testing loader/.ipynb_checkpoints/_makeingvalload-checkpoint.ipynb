{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74ba597f-563e-4f13-81f8-fbb10088d21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a32b280f-1e78-46d8-99fd-0a97c50b02df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class rando(Dataset):\n",
    "    \"\"\"\n",
    "    This dataloader loads random 5 minute intervals from a random patient.\n",
    "    \"\"\"\n",
    "    def __init__(self, ls_len, seed = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            path (str): path to the input & target folder.\n",
    "            series_dict (list): name of dict for data.\n",
    "            size : (number of experiments, number of max. channels, longest series)\n",
    "            device (class 'torch.device'): which pytorch device the data should\n",
    "            be sent to.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        self.length = ls_len\n",
    "        self.seed = seed\n",
    "        \n",
    "        if not(seed):\n",
    "            self.rng = np.random.default_rng(self.seed)\n",
    "            self.gen = iter(self.create_data(self.rng))\n",
    "        \n",
    "\n",
    "    def create_data(self, rng):\n",
    "        while True:\n",
    "            ind = rng.choice(10, 1)\n",
    "            yield ind\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.seed:\n",
    "            if idx == 0:\n",
    "                self.rng = np.random.default_rng(self.seed)\n",
    "                self.gen = iter(self.create_data(self.rng))\n",
    "            \n",
    "            \n",
    "        tal = next(self.gen)\n",
    "        return tal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "201d6c2e-f1c7-4656-b39c-3e82139baa99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9],\n",
      "        [2],\n",
      "        [6]])\n",
      "tensor([[8],\n",
      "        [0],\n",
      "        [0]])\n",
      "\n",
      "tensor([[4],\n",
      "        [5],\n",
      "        [7],\n",
      "        [9],\n",
      "        [0]])\n",
      "tensor([[1],\n",
      "        [8],\n",
      "        [9],\n",
      "        [2],\n",
      "        [3]])\n",
      "\n",
      "tensor([[7],\n",
      "        [1],\n",
      "        [9]])\n",
      "tensor([[6],\n",
      "        [4],\n",
      "        [6]])\n",
      "\n",
      "tensor([[4],\n",
      "        [5],\n",
      "        [7],\n",
      "        [9],\n",
      "        [0]])\n",
      "tensor([[1],\n",
      "        [8],\n",
      "        [9],\n",
      "        [2],\n",
      "        [3]])\n"
     ]
    }
   ],
   "source": [
    "train_file = rando(ls_len = 6)\n",
    "train_load = torch.utils.data.DataLoader(train_file,\n",
    "                                           batch_size=3,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=0)\n",
    "\n",
    "val_file = rando(ls_len = 10, seed = 1)\n",
    "val_loader = torch.utils.data.DataLoader(val_file,\n",
    "                                           batch_size=5,\n",
    "                                           shuffle=False,\n",
    "                                           num_workers=0)\n",
    "\n",
    "for i in train_load:\n",
    "    print(i)\n",
    "\n",
    "print()\n",
    "    \n",
    "for i in val_loader:\n",
    "    print(i)\n",
    "    \n",
    "print()\n",
    "    \n",
    "for i in train_load:\n",
    "    print(i)\n",
    "\n",
    "print()\n",
    "\n",
    "for i in val_loader:\n",
    "    print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b5a90a9-e623-4092-9b83-8021e640e8f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9 % (10-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61b6af7d-8023-4c0e-9087-8196a4b0560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class shuffle_5min(Dataset):\n",
    "    \"\"\"\n",
    "    This dataloader loads random 5 minute intervals from a random patient.\n",
    "    \"\"\"\n",
    "    def __init__(self, path: str, series_dict: str, size: tuple, device, seed = None, length = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            path (str): path to the input & target folder.\n",
    "            series_dict (list): name of dict for data.\n",
    "            size : (number of experiments, number of max. channels, longest series)\n",
    "            device (class 'torch.device'): which pytorch device the data should\n",
    "            be sent to.\n",
    "        \"\"\"\n",
    "\n",
    "        self.device = device\n",
    "        self.size = size\n",
    "        self.path = path\n",
    "        self.seed = seed\n",
    "        \n",
    "        with open(path + \"/\" + series_dict, 'rb') as handle:\n",
    "            self.s_dict = pickle.load(handle)\n",
    "\n",
    "        self.input_data = np.memmap(self.path + \"/model_input.dat\", dtype='float32', mode='r', shape=self.size)\n",
    "        self.target_data = np.memmap(self.path + \"/model_target.dat\", dtype='float32', mode='r', shape=self.size)\n",
    "\n",
    "        prop = [] # list with probabilities\n",
    "\n",
    "        ss = 0 # sum over all the batches\n",
    "        for val in self.s_dict.values():\n",
    "            prop.append(val[2])\n",
    "            ss += val[2]\n",
    "\n",
    "        self.prop = np.array(prop) / ss\n",
    "        \n",
    "        if length:\n",
    "            self.length = length\n",
    "        else:\n",
    "            self.length = ss\n",
    "\n",
    "        \n",
    "        if not(seed):\n",
    "            self.rng = np.random.default_rng(self.seed)\n",
    "            self.gen = iter(self.create_data(self.s_dict, self.rng))\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def create_data(self, s_dict, rng):\n",
    "        while True:\n",
    "            ind = rng.choice(self.size[0], 1, p = self.prop)\n",
    "            shp = s_dict[ind[0] + 1][3] # shape of experiment\n",
    "\n",
    "            cut_point = rng.integers(low = 200*30, #remove the first 30 secs\n",
    "                                high = shp[1] - 5*200*60, size = 1)\n",
    "                                # choose the place to cut\n",
    "\n",
    "            chan = rng.choice(shp[0], 1)\n",
    "\n",
    "            inp = self.input_data[ind[0], chan[0], cut_point[0]:cut_point[0]+60*5*200]\n",
    "            inp = torch.tensor(inp).view(1, 60*5*200)\n",
    "            tar = self.target_data[ind[0], chan[0], cut_point[0]:cut_point[0]+60*5*200]\n",
    "            tar = torch.tensor(tar).view(1, 60*5*200)\n",
    "            # #inp = self.ls[0][0][chan][cut_point[i]:cut_point[i]+60*5*200]\n",
    "            # #tar = self.ls[1][0][chan][cut_point[i]:cut_point[i]+60*5*200]\n",
    "\n",
    "            #tar = torch.cat((tar[0], -1*(tar[0] - 1))).view(2, 60*5*200)\n",
    "            yield inp, tar, (ind[0], chan[0], cut_point[0])\n",
    "\n",
    "\n",
    "    def clear_ram(self, index):\n",
    "        \"\"\"\n",
    "        This function is for clearing the ram.\n",
    "        \"\"\"\n",
    "        if index % 1000 == 0:\n",
    "            del self.input_data\n",
    "            del self.target_data\n",
    "            self.input_data = np.memmap(self.path + \"/model_input.dat\", dtype='float32', mode='r', shape=self.size)\n",
    "            self.target_data = np.memmap(self.path + \"/model_target.dat\", dtype='float32', mode='r', shape=self.size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.seed:\n",
    "            if idx == 0:\n",
    "                self.rng = np.random.default_rng(self.seed)\n",
    "                self.gen = iter(self.create_data(self.s_dict, self.rng))\n",
    "        \n",
    "        inp, tar, chan = next(self.gen)\n",
    "        inp = inp.to(self.device)\n",
    "        tar = tar.to(self.device)\n",
    "        self.clear_ram(idx)\n",
    "        return inp, tar, chan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eecf920d-1a05-48ce-97ab-db875f9e1d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "\n",
    "train_path = \"C:/Users/Marc/Desktop/model_data/train_model_data\"\n",
    "val_path = \"C:/Users/Marc/Desktop/model_data/val_model_data\"\n",
    "\n",
    "train_load_file = shuffle_5min(path = train_path,\n",
    "                                     series_dict = 'train_series_length.pickle',\n",
    "                                     size = (195, 22, 2060000),\n",
    "                                     device = \"cpu\",\n",
    "                                      length = 40)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_load_file,\n",
    "                                                batch_size=batch_size,\n",
    "                                                shuffle=True,\n",
    "                                                num_workers=0)\n",
    "\n",
    "val_load_file = shuffle_5min(path = val_path,\n",
    "                                     series_dict = 'val_series_length.pickle',\n",
    "                                     size = (28, 22, 549200),\n",
    "                                     device = \"cpu\",\n",
    "                                    seed = 42,\n",
    "                                    length=40)\n",
    "\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_load_file,\n",
    "                                                batch_size=batch_size,\n",
    "                                                shuffle=False,\n",
    "                                                num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e8d23e9-9b1a-469a-893b-d8374116cb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[ 3.3692e+00, -1.7878e-01, -6.9517e+00,  ..., -4.9875e+00,\n",
      "          -3.1621e+00, -2.1378e-01]],\n",
      "\n",
      "        [[ 4.7570e+01,  4.7928e+01,  4.8727e+01,  ...,  3.6561e+00,\n",
      "          -6.0309e-01, -1.2622e+00]],\n",
      "\n",
      "        [[ 8.9663e+00,  1.2249e+01,  1.4375e+01,  ..., -1.9211e+01,\n",
      "          -2.0450e+01, -3.3497e+01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 8.4972e+00,  4.6093e+00,  1.0953e+01,  ..., -4.5954e+00,\n",
      "          -2.0300e+00, -1.1172e+00]],\n",
      "\n",
      "        [[ 2.6758e+00,  8.8349e+00,  7.5782e+00,  ..., -2.0000e+02,\n",
      "          -2.0000e+02, -2.0000e+02]],\n",
      "\n",
      "        [[ 9.5479e+00,  7.0932e+00,  2.0422e+00,  ...,  5.4186e+01,\n",
      "           6.1281e+01,  1.1763e+02]]]), tensor([[[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.]]]), [tensor([ 96, 153, 102, 125, 194,  24,  90, 106,  60, 139, 175, 105,  95, 127,\n",
      "         24, 134, 160, 135,  71,  93]), tensor([ 6,  9, 12,  6,  5,  1, 19, 17,  9, 11, 19, 15,  5,  2, 19, 19, 19, 14,\n",
      "        16,  1]), tensor([ 39054,  47749, 123799,  15204, 289605, 126233, 126373,  89640,  80021,\n",
      "         63952, 148653,  14842,  87629,  10346, 205797, 111960, 335303,  26342,\n",
      "         31206,  39459])]]\n",
      "[tensor([[[ 14.8310,  14.5817,  12.9102,  ...,   5.4473,   6.2169,   8.7922]],\n",
      "\n",
      "        [[ -4.6479,  -3.2190,  -1.7825,  ...,  -0.0661,  -3.5233,  -6.9602]],\n",
      "\n",
      "        [[  6.9549,   7.4432,   7.4677,  ...,   9.8290,   9.1515,   8.4799]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-38.6718, -11.9832,  11.2299,  ..., -37.6842, -47.6011, -36.9317]],\n",
      "\n",
      "        [[ 44.2549,  37.6235,  39.6020,  ...,   6.1112,   6.5672,   5.3548]],\n",
      "\n",
      "        [[  9.2963, -12.3638,   6.3076,  ...,  -3.4312,  -2.2336, -10.7875]]]), tensor([[[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 0., 0., 0.]]]), [tensor([177, 159, 194,  55, 135, 161, 108, 181, 179, 150, 132, 148,  86, 133,\n",
      "        177,  17,  36, 155,  45,  76]), tensor([20,  3, 14, 15, 11,  6,  3, 11, 15, 12, 12, 20, 17,  8, 18,  7, 11, 14,\n",
      "         4, 16]), tensor([101350, 107012, 304719,  63844, 195695, 101858,  87762,  93736, 143656,\n",
      "        203769,  27066, 182859, 157027,  57080,  48310, 195661,  26915,  68873,\n",
      "        133712, 121485])]]\n",
      "\n",
      "[tensor([[[  2.4992,   0.4144,   0.7790,  ...,  -3.9081,  -3.1994,  -2.6711]],\n",
      "\n",
      "        [[ 17.5842,  20.0870,  21.4435,  ...,  -2.2328, -17.1336, -11.2634]],\n",
      "\n",
      "        [[  5.0988,  14.8754,   2.9928,  ...,  34.1649,  25.2707,  18.6957]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -0.0518,   0.7810,   1.0422,  ...,   0.2725,   0.2965,   1.3777]],\n",
      "\n",
      "        [[  0.5531,  -1.5886,   3.6882,  ...,   0.8975,   2.3712,   0.4896]],\n",
      "\n",
      "        [[ -0.8279,  -1.5176,  -2.5676,  ...,  -0.4574, -13.1413,  -4.2448]]]), tensor([[[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 0., 0., 0.]]]), [tensor([21, 23,  3, 21,  4, 10, 17, 11, 14, 22, 21, 27, 21, 11,  5, 20,  9, 11,\n",
      "         4,  6]), tensor([ 9, 15, 21, 17,  9, 20,  9,  4,  1, 13,  7, 18,  4,  0, 15, 18,  8,  4,\n",
      "        10, 14]), tensor([118717,  20782,  29165, 129549, 152452,  39443,  77066, 223662, 162446,\n",
      "         55041, 126630,  76062, 136854, 246532, 160473,  69575, 166279, 390472,\n",
      "        125721, 101964])]]\n",
      "[tensor([[[ 36.1956,  32.1574,  30.0021,  ..., -35.9322, -13.7208,  -2.7464]],\n",
      "\n",
      "        [[ 10.7608,   4.8195,  -6.8046,  ...,  13.1507,   9.4121,  10.6863]],\n",
      "\n",
      "        [[ -2.5332,  -1.1610,   1.5169,  ...,   4.0883,   1.5756,   8.1358]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-38.1765, -36.7623, -41.6380,  ...,  -5.3607,  -4.1325,  -5.8876]],\n",
      "\n",
      "        [[ 35.0321, -18.9784,  15.5386,  ...,  36.3886,  40.3752,   5.7191]],\n",
      "\n",
      "        [[ -8.1320, -10.4729,  -8.9407,  ...,   1.1520,  -1.8592,  -0.0623]]]), tensor([[[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 0., 0., 0.]]]), [tensor([11, 19, 23, 10, 18,  6, 21, 19, 11,  4, 18, 14, 17, 14,  1,  6, 23,  2,\n",
      "         8, 14]), tensor([18,  5, 17,  6,  3,  0, 14, 14, 12,  2, 10, 16,  6,  6,  9,  8,  5,  4,\n",
      "        14, 17]), tensor([ 83644,  22995,  80857, 170529, 113103, 142832, 140378,  54440, 250308,\n",
      "         48811, 116074,  19954, 105844, 146063,  69522,  53013,  11967, 161560,\n",
      "         84263,  94983])]]\n"
     ]
    }
   ],
   "source": [
    "for i in train_loader:\n",
    "    print(i)\n",
    "print()\n",
    "for i in val_loader:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f5bbf82-3459-40b5-bbde-b413ca60f2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "[1]\n",
      "[4]\n",
      "[2]\n",
      "[0]\n",
      "[6]\n",
      "\n",
      "[2]\n",
      "[1]\n",
      "[4]\n",
      "[2]\n",
      "[0]\n",
      "[6]\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "\n",
    "print(rng.choice(3, 1, p = [0, 0.5, 0.5]))\n",
    "print(rng.integers(low = 0, high = 3, size = 1))\n",
    "print(rng.choice(10, 1))\n",
    "\n",
    "print(rng.choice(3, 1, p = [0, 0.5, 0.5]))\n",
    "print(rng.integers(low = 0, high = 3, size = 1))\n",
    "print(rng.choice(10, 1))\n",
    "\n",
    "print()\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "print(rng.choice(3, 1, p = [0, 0.5, 0.5]))\n",
    "print(rng.integers(low = 0, high = 3, size = 1))\n",
    "print(rng.choice(10, 1))\n",
    "\n",
    "print(rng.choice(3, 1, p = [0, 0.5, 0.5]))\n",
    "print(rng.integers(low = 0, high = 3, size = 1))\n",
    "print(rng.choice(10, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae337b4e-1f9f-4248-a053-100efac44bad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
